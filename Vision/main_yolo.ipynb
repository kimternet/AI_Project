{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA 사용 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우쿨렐레 코드 운지를 정확히 인식하기 위해서는 이미지에서 작은 객체를 잘 감지할 수 있는 모델을 사용하는 것이 중요. YOLOv8 시리즈 중에서 가장 가벼운 모델인 YOLOv8n (nano)은 속도가 빠르고 가벼운 장점이 있지만, 정확도가 상대적으로 떨어질 수 있음. 반면에, YOLOv8s (small), YOLOv8m (medium), YOLOv8l (large), YOLOv8x (extra large)는 각각 더 많은 파라미터를 가지며, 정확도가 향상됨.\n",
    "\n",
    "추천 모델\n",
    "YOLOv8s (small): 모델의 크기와 속도, 정확도의 균형이 잘 맞음\n",
    "YOLOv8m (medium): 더 높은 정확도를 원한다면 이 모델이 적합할 수 있음\n",
    "모델 선택 기준\n",
    "속도: 실시간 성능이 중요한 경우 YOLOv8n이나 YOLOv8s가 적합함\n",
    "정확도: 정확도가 더 중요하다면 YOLOv8m 이상의 모델을 고려해 볼 수도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주요 지표 설명\n",
    "\n",
    "Precision (정밀도):\n",
    "metrics/precision(B): 0.985\n",
    "정밀도는 모델이 예측한 긍정 샘플 중 실제로 긍정인 샘플의 비율을 나타냄 높은 정밀도는 모델이 잘못된 긍정 예측을 적게 한다는 것을 의미\n",
    "\n",
    "Recall (재현율):\n",
    "metrics/recall(B): 0.984\n",
    "재현율은 실제 긍정 샘플 중 모델이 올바르게 예측한 샘플의 비율을 나타냅니다. 높은 재현율은 모델이 실제 긍정 샘플을 잘 놓치지 않는다는 것을 의미합니다.\n",
    "\n",
    "mAP50 (Mean Average Precision at IoU 0.5):\n",
    "metrics/mAP50(B): 0.994\n",
    "mAP50는 Intersection over Union (IoU) 임계값이 0.5일 때 평균 정밀도를 나타냅니다. 이는 모델의 정확한 객체 탐지 성능을 평가하는 지표입니다. 높은 mAP50 값은 모델이 객체를 정확히 탐지할 수 있다는 것을 의미합니다.\n",
    "\n",
    "mAP50-95 (Mean Average Precision at IoU 0.5 to 0.95):\n",
    "metrics/mAP50-95(B): 0.798\n",
    "mAP50-95는 IoU 임계값이 0.5에서 0.95까지 변화할 때 평균 정밀도를 나타냅니다. 이 값은 모델의 전반적인 객체 탐지 성능을 평가하는 지표입니다. mAP50-95 값이 높을수록 모델이 다양한 IoU 임계값에서 우수한 성능을 보입니다.\n",
    "\n",
    "Class-wise 성능:\n",
    "all: 모델의 전체적인 성능 요약\n",
    "Am: Am 클래스에 대한 성능 요약\n",
    "Box(P) (박스 정밀도): 0.985\n",
    "R (재현율): 0.984\n",
    "mAP50: 0.994\n",
    "mAP50-95: 0.798\n",
    "각 클래스별 성능을 나타내며, 박스 정밀도, 재현율, mAP50, mAP50-95 값을 제공.\n",
    "\n",
    "속도 (Speed):\n",
    "preprocess: 0.2ms (전처리 시간)\n",
    "inference: 6.3ms (추론 시간)\n",
    "loss: 0.0ms (손실 계산 시간)\n",
    "postprocess: 0.8ms (후처리 시간)\n",
    "모델의 처리 속도를 나타냄. 이는 한 이미지당 평균 소요 시간을 의미함. 빠른 처리 시간은 실시간 애플리케이션에 유리함.\n",
    "\n",
    "요약\n",
    "모델의 성능은 매우 우수함 높은 정밀도와 재현율, mAP50, mAP50-95 값을 보이며, 이는 모델이 객체를 정확하게 탐지하고 대부분의 객체를 놓치지 않는다는 것을 의미함. 또한, 속도 측면에서도 효율적.\n",
    "\n",
    "추가 작업\n",
    "평가 결과를 바탕으로 모델을 개선하거나 추가 실험을 수행할 수 있음 예를 들어, 특정 클래스의 성능을 더 향상시키거나, 모델을 경량화하여 추론 속도를 더욱 빠르게 할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\3gkim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\3gkim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\3gkim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\3gkim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\3gkim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\3gkim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\3gkim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\3gkim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\3gkim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\3gkim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\3gkim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\3gkim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==1.10.0+cu111 (from versions: 2.2.0, 2.2.0+cpu, 2.2.0+cu118, 2.2.0+cu121, 2.2.1, 2.2.1+cpu, 2.2.1+cu118, 2.2.1+cu121, 2.2.2, 2.2.2+cpu, 2.2.2+cu118, 2.2.2+cu121, 2.3.0, 2.3.0+cpu, 2.3.0+cu118, 2.3.0+cu121, 2.3.1, 2.3.1+cpu, 2.3.1+cu118, 2.3.1+cu121)\n",
      "ERROR: No matching distribution found for torch==1.10.0+cu111\n"
     ]
    }
   ],
   "source": [
    "pip install torch==1.10.0+cu111 torchvision==0.11.1+cu111 torchaudio==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "CUDA device name: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "CUDA device name: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Train data:\n",
      "Class Am: 1329 images, 1330 labels\n",
      "Class C: 1343 images, 1343 labels\n",
      "Class F: 1311 images, 1312 labels\n",
      "Class G: 1307 images, 1308 labels\n",
      "Validation data:\n",
      "Class Am: 250 images, 251 labels\n",
      "Class C: 251 images, 251 labels\n",
      "Class F: 250 images, 251 labels\n",
      "Class G: 250 images, 251 labels\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# CUDA 정보 출력\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# 모델 불러오기\n",
    "model = YOLO('yolov8s.yaml')  # small 모델 사용\n",
    "\n",
    "# 데이터 경로 확인 및 프린트\n",
    "train_dir = 'C:/Users/3gkim/OneDrive/Desktop/YOLO/train'\n",
    "val_dir = 'C:/Users/3gkim/OneDrive/Desktop/YOLO/val'\n",
    "\n",
    "def check_data_dir(data_dir, class_names):\n",
    "    for cls in class_names:\n",
    "        cls_path = os.path.join(data_dir, cls)\n",
    "        if not os.path.exists(cls_path):\n",
    "            print(f\"Class directory {cls_path} does not exist!\")\n",
    "        else:\n",
    "            images = [f for f in os.listdir(cls_path) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "            labels = [f for f in os.listdir(cls_path) if f.endswith('.txt')]\n",
    "            print(f\"Class {cls}: {len(images)} images, {len(labels)} labels\")\n",
    "\n",
    "class_names = ['Am', 'C', 'F', 'G']\n",
    "print(\"Train data:\")\n",
    "check_data_dir(train_dir, class_names)\n",
    "\n",
    "print(\"Validation data:\")\n",
    "check_data_dir(val_dir, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.62 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.60  Python-3.12.4 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.yaml, data=C:/Users/3gkim/OneDrive/Desktop/YOLO/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=480, save=True, save_period=-1, cache=False, device=0, workers=8, project=runs, name=ukulele_chords_detection36, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\ukulele_chords_detection36\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117596  ultralytics.nn.modules.head.Detect           [4, [128, 256, 512]]          \n",
      "YOLOv8s summary: 225 layers, 11,137,148 parameters, 11,137,132 gradients, 28.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\ukulele_chords_detection36', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\3gkim\\OneDrive\\Desktop\\YOLO\\train\\Am.cache... 5289 images, 6 backgrounds, 0 corrupt: 100%|██████████| 5290/5290 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\3gkim\\OneDrive\\Desktop\\YOLO\\val\\Am.cache... 1000 images, 2 backgrounds, 0 corrupt: 100%|██████████| 1001/1001 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\ukulele_chords_detection36\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 480 train, 480 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\ukulele_chords_detection36\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      2.44G      2.571      3.325       3.41         14        480: 100%|██████████| 331/331 [01:16<00:00,  4.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:07<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.168      0.229      0.143     0.0593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50       2.4G       1.76      2.266        2.4         20        480: 100%|██████████| 331/331 [01:12<00:00,  4.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005       0.36      0.486      0.273      0.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      2.39G       1.56      1.935       2.17         19        480: 100%|██████████| 331/331 [01:10<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:07<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.248      0.683      0.351      0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      2.37G      1.483      1.786      2.075         14        480: 100%|██████████| 331/331 [01:13<00:00,  4.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.365      0.597      0.425       0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      2.36G      1.408      1.631      1.993         15        480: 100%|██████████| 331/331 [04:05<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:19<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.497      0.643      0.571      0.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      2.39G      1.367      1.511      1.944         14        480: 100%|██████████| 331/331 [04:19<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.507      0.636      0.572      0.319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      2.35G      1.337      1.418      1.912         21        480: 100%|██████████| 331/331 [04:19<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.439      0.613      0.531      0.329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      2.36G      1.296      1.329      1.872         19        480: 100%|██████████| 331/331 [04:16<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.562      0.602      0.648       0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      2.36G      1.263      1.271      1.834         20        480: 100%|██████████| 331/331 [04:18<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.614      0.716      0.712       0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      2.39G      1.217      1.216      1.796         19        480: 100%|██████████| 331/331 [04:18<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.675      0.687      0.762      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      2.35G      1.226      1.172      1.796         17        480: 100%|██████████| 331/331 [04:16<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.746      0.794      0.853      0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      2.36G      1.196      1.116      1.772         18        480: 100%|██████████| 331/331 [04:13<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.777       0.76      0.866      0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      2.37G      1.165      1.103      1.738         21        480: 100%|██████████| 331/331 [04:19<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.808      0.728      0.828      0.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      2.39G      1.151       1.05      1.728         18        480: 100%|██████████| 331/331 [01:20<00:00,  4.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.809      0.755      0.879      0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      2.35G      1.138      1.039      1.715         14        480: 100%|██████████| 331/331 [01:43<00:00,  3.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.803      0.738      0.843      0.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      2.36G      1.122      1.016      1.696         23        480: 100%|██████████| 331/331 [04:17<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.885      0.834      0.924      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      2.37G      1.098     0.9743      1.687         14        480: 100%|██████████| 331/331 [01:18<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.845      0.847       0.93      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      2.39G      1.084     0.9536      1.677         17        480: 100%|██████████| 331/331 [01:12<00:00,  4.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.886      0.884      0.943      0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      2.35G      1.086     0.9471      1.672         14        480: 100%|██████████| 331/331 [03:47<00:00,  1.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.874      0.852      0.922      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      2.36G      1.061     0.9221      1.641         21        480: 100%|██████████| 331/331 [01:10<00:00,  4.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.912      0.888       0.95      0.666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      2.36G      1.059     0.9137      1.639         19        480: 100%|██████████| 331/331 [02:23<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.876      0.878      0.942      0.658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      2.38G      1.035     0.8766      1.614         19        480: 100%|██████████| 331/331 [02:43<00:00,  2.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.879      0.837      0.919      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      2.35G       1.04     0.8746      1.625         17        480: 100%|██████████| 331/331 [01:10<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.914      0.899       0.96      0.681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      2.37G      1.018     0.8627       1.61         22        480: 100%|██████████| 331/331 [03:16<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.923      0.905      0.963      0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      2.37G      1.022     0.8536      1.605         21        480: 100%|██████████| 331/331 [01:51<00:00,  2.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.934      0.924      0.976      0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      2.39G     0.9958     0.8209      1.584         23        480: 100%|██████████| 331/331 [01:14<00:00,  4.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:19<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.943      0.917      0.971      0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      2.35G      1.005     0.8355        1.6         24        480: 100%|██████████| 331/331 [04:17<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.928      0.935      0.969      0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      2.37G     0.9896     0.8176      1.579         20        480: 100%|██████████| 331/331 [02:01<00:00,  2.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:07<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.935      0.906       0.97      0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      2.36G     0.9659     0.7866      1.554         20        480: 100%|██████████| 331/331 [01:10<00:00,  4.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.947      0.937      0.978       0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      2.39G     0.9689     0.7858      1.555         23        480: 100%|██████████| 331/331 [03:55<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:18<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.938      0.946       0.98      0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      2.35G     0.9481      0.777      1.541         15        480: 100%|██████████| 331/331 [01:10<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.956      0.919      0.978       0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      2.37G     0.9578      0.762      1.549         15        480: 100%|██████████| 331/331 [01:51<00:00,  2.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.963      0.942      0.981      0.729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      2.36G     0.9451     0.7613      1.539         16        480: 100%|██████████| 331/331 [03:12<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.945      0.952      0.983      0.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50       2.4G     0.9343     0.7372      1.522         21        480: 100%|██████████| 331/331 [01:10<00:00,  4.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.965      0.952      0.982      0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      2.35G     0.9291     0.7313      1.525         21        480: 100%|██████████| 331/331 [02:42<00:00,  2.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:19<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.959      0.956      0.981      0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      2.36G     0.9248     0.7283      1.524         18        480: 100%|██████████| 331/331 [02:10<00:00,  2.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.957       0.96      0.984       0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      2.36G     0.9145      0.723      1.509         17        480: 100%|██████████| 331/331 [01:11<00:00,  4.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005       0.96      0.963      0.984       0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      2.39G     0.8987     0.7043      1.494         18        480: 100%|██████████| 331/331 [03:55<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:12<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.976      0.965      0.986      0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      2.35G     0.9002     0.6942      1.492         21        480: 100%|██████████| 331/331 [01:10<00:00,  4.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.976      0.965      0.986       0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      2.37G     0.8927     0.6756      1.494         21        480: 100%|██████████| 331/331 [02:18<00:00,  2.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.964      0.971      0.987      0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      2.37G     0.7515      0.402      1.407         10        480: 100%|██████████| 331/331 [02:22<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.983      0.967       0.99      0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      2.39G     0.7396     0.3906      1.396         10        480: 100%|██████████| 331/331 [01:11<00:00,  4.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.979      0.965      0.988      0.786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      2.35G     0.7288     0.3839       1.38         10        480: 100%|██████████| 331/331 [03:23<00:00,  1.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.972      0.979       0.99      0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      2.36G     0.7206     0.3758      1.373         10        480: 100%|██████████| 331/331 [01:22<00:00,  4.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.982      0.976      0.991      0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      2.36G     0.7019     0.3677       1.35         10        480: 100%|██████████| 331/331 [01:20<00:00,  4.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.979      0.981      0.992      0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      2.38G     0.6966     0.3576      1.343         10        480: 100%|██████████| 331/331 [03:32<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005       0.98      0.978      0.992      0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      2.35G     0.6805     0.3544      1.333         10        480: 100%|██████████| 331/331 [01:10<00:00,  4.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.982      0.981      0.991      0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      2.36G     0.6773     0.3473      1.326         10        480: 100%|██████████| 331/331 [02:23<00:00,  2.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:20<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.986      0.987      0.992      0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      2.36G     0.6663     0.3437      1.319         10        480: 100%|██████████| 331/331 [02:26<00:00,  2.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.983      0.986      0.993      0.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      2.39G     0.6591     0.3412      1.307         10        480: 100%|██████████| 331/331 [01:10<00:00,  4.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:06<00:00,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.988      0.987      0.991      0.823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 2.264 hours.\n",
      "Optimizer stripped from runs\\ukulele_chords_detection36\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from runs\\ukulele_chords_detection36\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating runs\\ukulele_chords_detection36\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.60  Python-3.12.4 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLOv8s summary (fused): 168 layers, 11,127,132 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 32/32 [00:07<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.988      0.987      0.991      0.823\n",
      "                    Am        253        255      0.994       0.98      0.993      0.828\n",
      "                     C        250        250      0.991      0.996      0.991      0.852\n",
      "                     F        247        247      0.984      0.986      0.994      0.838\n",
      "                     G        249        253      0.982      0.984      0.988      0.773\n",
      "Speed: 0.1ms preprocess, 3.7ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\ukulele_chords_detection36\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "model = YOLO('yolov8s.yaml')  # small 모델 사용\n",
    "\n",
    "# 모델 학습\n",
    "model.train(\n",
    "    data='C:/Users/3gkim/OneDrive/Desktop/YOLO/data.yaml', \n",
    "    epochs=50, \n",
    "    imgsz=480, \n",
    "    batch=16,\n",
    "    name='ukulele_chords_detection3', \n",
    "    device='0',\n",
    "    project='runs'  # 로그 파일 생성 경로 설정\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 학습 중 진행 상황 확인 (에포크별 손실 값 및 평가 지표)\n",
    "def print_training_progress(epoch, logs):\n",
    "    print(f\"Epoch {epoch+1}/{30}\")\n",
    "    print(f\" - box_loss: {logs['box_loss']:.4f}\")\n",
    "    print(f\" - cls_loss: {logs['cls_loss']:.4f}\")\n",
    "    print(f\" - dfl_loss: {logs['dfl_loss']:.4f}\")\n",
    "\n",
    "# 학습 진행 상황을 로그에 기록\n",
    "model.add_callback('on_epoch_end', print_training_progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습완료 후 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.60  Python-3.12.4 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLOv8s summary (fused): 168 layers, 11,127,132 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\3gkim\\OneDrive\\Desktop\\YOLO\\val\\Am.cache... 1000 images, 2 backgrounds, 0 corrupt: 100%|██████████| 1001/1001 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 63/63 [00:10<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1001       1005      0.988      0.987      0.991      0.822\n",
      "                    Am        253        255      0.994       0.98      0.993      0.827\n",
      "                     C        250        250      0.991      0.996      0.991      0.851\n",
      "                     F        247        247      0.984      0.986      0.994      0.839\n",
      "                     G        249        253      0.982      0.984      0.988      0.771\n",
      "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\ukulele_chords_detection362\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 모델 평가\n",
    "results = model.val()\n",
    "\n",
    "# ConfusionMatrix 객체의 속성 및 내용 확인\n",
    "confusion_matrix = results.confusion_matrix\n",
    "matrix = confusion_matrix.matrix  # 혼동 행렬 데이터 추출\n",
    "\n",
    "# 데이터가 2차원 배열인지 확인\n",
    "if isinstance(matrix, np.ndarray) and matrix.ndim == 2:\n",
    "    # 클래스 이름 설정\n",
    "    class_names = ['Am', 'C', 'F', 'G']  # 실제 클래스 이름으로 설정\n",
    "\n",
    "    # 혼동 행렬 시각화\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(matrix, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Matrix is not in the expected 2D array format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in c:\\users\\ksanz\\anaconda3\\lib\\site-packages (2.90)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: comtypes in c:\\users\\ksanz\\anaconda3\\lib\\site-packages (from pyttsx3) (1.4.5)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\ksanz\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\ksanz\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n"
     ]
    }
   ],
   "source": [
    "pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x480 (no detections), 133.9ms\n",
      "Speed: 3.5ms preprocess, 133.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 141.0ms\n",
      "Speed: 2.5ms preprocess, 141.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 167.5ms\n",
      "Speed: 2.0ms preprocess, 167.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.6ms\n",
      "Speed: 2.0ms preprocess, 165.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 177.1ms\n",
      "Speed: 2.0ms preprocess, 177.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.2ms\n",
      "Speed: 3.0ms preprocess, 165.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 167.2ms\n",
      "Speed: 2.0ms preprocess, 167.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.8ms\n",
      "Speed: 2.3ms preprocess, 160.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.3ms\n",
      "Speed: 1.5ms preprocess, 164.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.3ms\n",
      "Speed: 3.0ms preprocess, 165.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.2ms\n",
      "Speed: 2.0ms preprocess, 164.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 159.7ms\n",
      "Speed: 2.0ms preprocess, 159.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.4ms\n",
      "Speed: 2.0ms preprocess, 163.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 168.9ms\n",
      "Speed: 2.0ms preprocess, 168.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 162.2ms\n",
      "Speed: 1.5ms preprocess, 162.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 2 Gs, 168.9ms\n",
      "Speed: 2.5ms preprocess, 168.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 172.0ms\n",
      "Speed: 2.0ms preprocess, 172.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 169.3ms\n",
      "Speed: 3.5ms preprocess, 169.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 159.7ms\n",
      "Speed: 3.0ms preprocess, 159.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.7ms\n",
      "Speed: 1.0ms preprocess, 160.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.8ms\n",
      "Speed: 2.0ms preprocess, 161.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.0ms\n",
      "Speed: 2.0ms preprocess, 163.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 165.7ms\n",
      "Speed: 3.0ms preprocess, 165.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 164.4ms\n",
      "Speed: 3.0ms preprocess, 164.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 1 G, 165.1ms\n",
      "Speed: 1.5ms preprocess, 165.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 1 G, 186.7ms\n",
      "Speed: 1.5ms preprocess, 186.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 167.2ms\n",
      "Speed: 3.0ms preprocess, 167.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.6ms\n",
      "Speed: 3.0ms preprocess, 163.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 158.9ms\n",
      "Speed: 3.6ms preprocess, 158.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 164.1ms\n",
      "Speed: 2.0ms preprocess, 164.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 158.5ms\n",
      "Speed: 3.0ms preprocess, 158.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 163.3ms\n",
      "Speed: 2.0ms preprocess, 163.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 165.7ms\n",
      "Speed: 2.0ms preprocess, 165.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.0ms\n",
      "Speed: 2.0ms preprocess, 164.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 162.2ms\n",
      "Speed: 2.0ms preprocess, 162.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 167.0ms\n",
      "Speed: 3.0ms preprocess, 167.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.1ms\n",
      "Speed: 1.5ms preprocess, 164.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.6ms\n",
      "Speed: 2.5ms preprocess, 165.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 166.9ms\n",
      "Speed: 2.0ms preprocess, 166.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.0ms\n",
      "Speed: 3.0ms preprocess, 161.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.6ms\n",
      "Speed: 3.0ms preprocess, 161.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 159.4ms\n",
      "Speed: 3.0ms preprocess, 159.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.5ms\n",
      "Speed: 2.5ms preprocess, 163.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.7ms\n",
      "Speed: 2.0ms preprocess, 160.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 156.3ms\n",
      "Speed: 1.0ms preprocess, 156.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 157.5ms\n",
      "Speed: 2.5ms preprocess, 157.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.6ms\n",
      "Speed: 2.0ms preprocess, 161.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 154.7ms\n",
      "Speed: 2.0ms preprocess, 154.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 156.3ms\n",
      "Speed: 3.5ms preprocess, 156.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.4ms\n",
      "Speed: 2.0ms preprocess, 164.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 159.0ms\n",
      "Speed: 2.0ms preprocess, 159.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.5ms\n",
      "Speed: 3.0ms preprocess, 164.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 167.0ms\n",
      "Speed: 2.0ms preprocess, 167.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.0ms\n",
      "Speed: 1.5ms preprocess, 163.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 183.1ms\n",
      "Speed: 2.0ms preprocess, 183.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 187.2ms\n",
      "Speed: 4.0ms preprocess, 187.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 167.8ms\n",
      "Speed: 1.5ms preprocess, 167.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.2ms\n",
      "Speed: 2.0ms preprocess, 160.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.5ms\n",
      "Speed: 3.0ms preprocess, 160.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 167.5ms\n",
      "Speed: 3.5ms preprocess, 167.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.7ms\n",
      "Speed: 3.0ms preprocess, 161.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 167.1ms\n",
      "Speed: 3.0ms preprocess, 167.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.8ms\n",
      "Speed: 3.0ms preprocess, 161.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.5ms\n",
      "Speed: 3.0ms preprocess, 165.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 151.0ms\n",
      "Speed: 2.0ms preprocess, 151.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 155.5ms\n",
      "Speed: 2.0ms preprocess, 155.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 153.4ms\n",
      "Speed: 1.5ms preprocess, 153.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 152.0ms\n",
      "Speed: 1.5ms preprocess, 152.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 150.5ms\n",
      "Speed: 2.0ms preprocess, 150.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 146.9ms\n",
      "Speed: 2.0ms preprocess, 146.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 149.4ms\n",
      "Speed: 2.0ms preprocess, 149.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 150.7ms\n",
      "Speed: 2.0ms preprocess, 150.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 158.6ms\n",
      "Speed: 2.5ms preprocess, 158.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 158.1ms\n",
      "Speed: 1.0ms preprocess, 158.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 162.7ms\n",
      "Speed: 3.0ms preprocess, 162.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 162.6ms\n",
      "Speed: 2.0ms preprocess, 162.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.6ms\n",
      "Speed: 2.0ms preprocess, 164.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.6ms\n",
      "Speed: 3.5ms preprocess, 165.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.9ms\n",
      "Speed: 3.0ms preprocess, 165.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.5ms\n",
      "Speed: 2.0ms preprocess, 163.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 154.9ms\n",
      "Speed: 2.0ms preprocess, 154.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 166.9ms\n",
      "Speed: 2.0ms preprocess, 166.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 167.2ms\n",
      "Speed: 1.0ms preprocess, 167.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.0ms\n",
      "Speed: 2.0ms preprocess, 160.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.2ms\n",
      "Speed: 3.0ms preprocess, 165.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 162.0ms\n",
      "Speed: 3.0ms preprocess, 162.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.0ms\n",
      "Speed: 3.5ms preprocess, 161.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 166.6ms\n",
      "Speed: 2.0ms preprocess, 166.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.5ms\n",
      "Speed: 3.0ms preprocess, 165.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.3ms\n",
      "Speed: 2.0ms preprocess, 160.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.1ms\n",
      "Speed: 2.0ms preprocess, 163.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.1ms\n",
      "Speed: 2.0ms preprocess, 163.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.0ms\n",
      "Speed: 3.5ms preprocess, 160.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.6ms\n",
      "Speed: 3.0ms preprocess, 161.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 159.0ms\n",
      "Speed: 2.5ms preprocess, 159.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.4ms\n",
      "Speed: 3.5ms preprocess, 160.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 167.5ms\n",
      "Speed: 2.5ms preprocess, 167.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.3ms\n",
      "Speed: 3.0ms preprocess, 161.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 170.7ms\n",
      "Speed: 3.0ms preprocess, 170.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 170.1ms\n",
      "Speed: 2.0ms preprocess, 170.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 167.2ms\n",
      "Speed: 3.0ms preprocess, 167.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.9ms\n",
      "Speed: 2.0ms preprocess, 163.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 162.9ms\n",
      "Speed: 3.0ms preprocess, 162.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 166.0ms\n",
      "Speed: 3.0ms preprocess, 166.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 162.8ms\n",
      "Speed: 1.5ms preprocess, 162.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.5ms\n",
      "Speed: 3.5ms preprocess, 164.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 168.2ms\n",
      "Speed: 2.0ms preprocess, 168.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 189.0ms\n",
      "Speed: 4.0ms preprocess, 189.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 176.9ms\n",
      "Speed: 3.5ms preprocess, 176.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 168.9ms\n",
      "Speed: 2.0ms preprocess, 168.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 168.9ms\n",
      "Speed: 2.5ms preprocess, 168.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 188.8ms\n",
      "Speed: 3.0ms preprocess, 188.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 159.8ms\n",
      "Speed: 1.0ms preprocess, 159.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 153.8ms\n",
      "Speed: 1.5ms preprocess, 153.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.9ms\n",
      "Speed: 3.0ms preprocess, 161.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.3ms\n",
      "Speed: 3.0ms preprocess, 160.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 152.9ms\n",
      "Speed: 2.5ms preprocess, 152.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 154.1ms\n",
      "Speed: 3.0ms preprocess, 154.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.5ms\n",
      "Speed: 1.0ms preprocess, 160.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.0ms\n",
      "Speed: 3.5ms preprocess, 161.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 168.4ms\n",
      "Speed: 3.0ms preprocess, 168.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.0ms\n",
      "Speed: 1.0ms preprocess, 161.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 156.4ms\n",
      "Speed: 2.5ms preprocess, 156.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 162.5ms\n",
      "Speed: 3.0ms preprocess, 162.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.5ms\n",
      "Speed: 2.0ms preprocess, 165.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.0ms\n",
      "Speed: 3.0ms preprocess, 164.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 167.6ms\n",
      "Speed: 2.0ms preprocess, 167.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 157.6ms\n",
      "Speed: 3.0ms preprocess, 157.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 154.3ms\n",
      "Speed: 2.0ms preprocess, 154.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 146.9ms\n",
      "Speed: 2.0ms preprocess, 146.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 148.5ms\n",
      "Speed: 3.0ms preprocess, 148.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 157.1ms\n",
      "Speed: 3.0ms preprocess, 157.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 149.9ms\n",
      "Speed: 4.5ms preprocess, 149.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 149.8ms\n",
      "Speed: 2.0ms preprocess, 149.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 150.4ms\n",
      "Speed: 2.0ms preprocess, 150.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 152.8ms\n",
      "Speed: 3.5ms preprocess, 152.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 161.0ms\n",
      "Speed: 3.0ms preprocess, 161.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 170.1ms\n",
      "Speed: 3.5ms preprocess, 170.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 164.0ms\n",
      "Speed: 2.5ms preprocess, 164.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 158.2ms\n",
      "Speed: 3.0ms preprocess, 158.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 158.5ms\n",
      "Speed: 2.0ms preprocess, 158.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 164.5ms\n",
      "Speed: 3.0ms preprocess, 164.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 186.1ms\n",
      "Speed: 3.0ms preprocess, 186.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 158.6ms\n",
      "Speed: 2.0ms preprocess, 158.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 168.5ms\n",
      "Speed: 2.5ms preprocess, 168.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 164.0ms\n",
      "Speed: 2.5ms preprocess, 164.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 167.5ms\n",
      "Speed: 2.0ms preprocess, 167.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 161.4ms\n",
      "Speed: 2.0ms preprocess, 161.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 164.1ms\n",
      "Speed: 1.0ms preprocess, 164.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 2 Gs, 159.6ms\n",
      "Speed: 3.5ms preprocess, 159.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 165.5ms\n",
      "Speed: 1.0ms preprocess, 165.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 162.4ms\n",
      "Speed: 2.0ms preprocess, 162.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 164.1ms\n",
      "Speed: 2.0ms preprocess, 164.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 163.1ms\n",
      "Speed: 3.0ms preprocess, 163.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 166.9ms\n",
      "Speed: 2.0ms preprocess, 166.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 G, 160.5ms\n",
      "Speed: 2.0ms preprocess, 160.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 162.1ms\n",
      "Speed: 3.5ms preprocess, 162.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 G, 158.5ms\n",
      "Speed: 1.5ms preprocess, 158.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 G, 157.4ms\n",
      "Speed: 2.0ms preprocess, 157.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 161.0ms\n",
      "Speed: 3.0ms preprocess, 161.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 2 Gs, 162.7ms\n",
      "Speed: 2.0ms preprocess, 162.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 2 Gs, 164.0ms\n",
      "Speed: 2.0ms preprocess, 164.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 2 Gs, 166.7ms\n",
      "Speed: 1.0ms preprocess, 166.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 2 Gs, 157.1ms\n",
      "Speed: 2.5ms preprocess, 157.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 2 Gs, 163.6ms\n",
      "Speed: 3.0ms preprocess, 163.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 2 Gs, 159.6ms\n",
      "Speed: 1.0ms preprocess, 159.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 164.3ms\n",
      "Speed: 4.0ms preprocess, 164.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 165.6ms\n",
      "Speed: 2.5ms preprocess, 165.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 158.5ms\n",
      "Speed: 3.0ms preprocess, 158.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 157.5ms\n",
      "Speed: 2.0ms preprocess, 157.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 163.3ms\n",
      "Speed: 1.5ms preprocess, 163.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 F, 154.5ms\n",
      "Speed: 2.0ms preprocess, 154.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 164.3ms\n",
      "Speed: 3.0ms preprocess, 164.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 150.0ms\n",
      "Speed: 2.1ms preprocess, 150.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 154.1ms\n",
      "Speed: 3.0ms preprocess, 154.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 F, 155.7ms\n",
      "Speed: 1.0ms preprocess, 155.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 F, 153.0ms\n",
      "Speed: 2.0ms preprocess, 153.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 149.9ms\n",
      "Speed: 2.0ms preprocess, 149.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 150.6ms\n",
      "Speed: 2.0ms preprocess, 150.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 149.7ms\n",
      "Speed: 2.0ms preprocess, 149.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 149.0ms\n",
      "Speed: 2.0ms preprocess, 149.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 165.2ms\n",
      "Speed: 2.5ms preprocess, 165.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 2 Gs, 162.5ms\n",
      "Speed: 3.0ms preprocess, 162.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 162.0ms\n",
      "Speed: 2.0ms preprocess, 162.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 159.5ms\n",
      "Speed: 2.0ms preprocess, 159.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 169.0ms\n",
      "Speed: 3.0ms preprocess, 169.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 162.5ms\n",
      "Speed: 3.0ms preprocess, 162.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 162.8ms\n",
      "Speed: 1.0ms preprocess, 162.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 155.9ms\n",
      "Speed: 2.0ms preprocess, 155.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 1 G, 169.7ms\n",
      "Speed: 3.5ms preprocess, 169.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 1 G, 166.1ms\n",
      "Speed: 3.5ms preprocess, 166.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 1 G, 160.4ms\n",
      "Speed: 2.0ms preprocess, 160.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 1 G, 162.2ms\n",
      "Speed: 2.0ms preprocess, 162.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 162.8ms\n",
      "Speed: 3.5ms preprocess, 162.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 170.2ms\n",
      "Speed: 3.0ms preprocess, 170.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 157.0ms\n",
      "Speed: 1.5ms preprocess, 157.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 163.9ms\n",
      "Speed: 3.0ms preprocess, 163.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 1 G, 166.4ms\n",
      "Speed: 2.0ms preprocess, 166.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 159.9ms\n",
      "Speed: 3.0ms preprocess, 159.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.5ms\n",
      "Speed: 3.0ms preprocess, 161.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.9ms\n",
      "Speed: 2.5ms preprocess, 165.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 160.8ms\n",
      "Speed: 2.0ms preprocess, 160.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 165.7ms\n",
      "Speed: 3.0ms preprocess, 165.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 165.4ms\n",
      "Speed: 2.0ms preprocess, 165.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 166.9ms\n",
      "Speed: 3.5ms preprocess, 166.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 160.3ms\n",
      "Speed: 3.0ms preprocess, 160.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 171.0ms\n",
      "Speed: 3.0ms preprocess, 171.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 167.6ms\n",
      "Speed: 2.0ms preprocess, 167.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 167.1ms\n",
      "Speed: 3.0ms preprocess, 167.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 167.6ms\n",
      "Speed: 3.0ms preprocess, 167.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 161.5ms\n",
      "Speed: 3.0ms preprocess, 161.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 167.4ms\n",
      "Speed: 3.0ms preprocess, 167.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 169.4ms\n",
      "Speed: 1.5ms preprocess, 169.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 160.4ms\n",
      "Speed: 2.0ms preprocess, 160.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 159.5ms\n",
      "Speed: 2.0ms preprocess, 159.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.2ms\n",
      "Speed: 3.0ms preprocess, 163.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.8ms\n",
      "Speed: 2.0ms preprocess, 163.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.1ms\n",
      "Speed: 3.0ms preprocess, 163.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 158.8ms\n",
      "Speed: 3.5ms preprocess, 158.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 148.9ms\n",
      "Speed: 3.0ms preprocess, 148.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.0ms\n",
      "Speed: 3.0ms preprocess, 160.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 159.8ms\n",
      "Speed: 2.5ms preprocess, 159.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 153.0ms\n",
      "Speed: 3.0ms preprocess, 153.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 146.5ms\n",
      "Speed: 3.0ms preprocess, 146.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 149.4ms\n",
      "Speed: 3.0ms preprocess, 149.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 154.8ms\n",
      "Speed: 2.0ms preprocess, 154.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 166.6ms\n",
      "Speed: 3.0ms preprocess, 166.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.5ms\n",
      "Speed: 3.0ms preprocess, 164.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 165.8ms\n",
      "Speed: 3.0ms preprocess, 165.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.9ms\n",
      "Speed: 3.5ms preprocess, 160.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.1ms\n",
      "Speed: 2.5ms preprocess, 161.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 168.2ms\n",
      "Speed: 1.0ms preprocess, 168.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 161.1ms\n",
      "Speed: 2.0ms preprocess, 161.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 163.7ms\n",
      "Speed: 3.0ms preprocess, 163.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 164.5ms\n",
      "Speed: 3.0ms preprocess, 164.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 168.0ms\n",
      "Speed: 1.0ms preprocess, 168.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 166.6ms\n",
      "Speed: 2.0ms preprocess, 166.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 166.1ms\n",
      "Speed: 3.0ms preprocess, 166.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 163.5ms\n",
      "Speed: 2.5ms preprocess, 163.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 167.0ms\n",
      "Speed: 3.0ms preprocess, 167.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 163.2ms\n",
      "Speed: 1.5ms preprocess, 163.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 159.9ms\n",
      "Speed: 2.5ms preprocess, 159.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 167.0ms\n",
      "Speed: 3.2ms preprocess, 167.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 157.5ms\n",
      "Speed: 2.0ms preprocess, 157.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 162.8ms\n",
      "Speed: 3.0ms preprocess, 162.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.9ms\n",
      "Speed: 3.0ms preprocess, 160.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.0ms\n",
      "Speed: 2.0ms preprocess, 160.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 167.8ms\n",
      "Speed: 3.5ms preprocess, 167.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 168.0ms\n",
      "Speed: 3.0ms preprocess, 168.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 158.5ms\n",
      "Speed: 2.0ms preprocess, 158.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 G, 163.0ms\n",
      "Speed: 2.0ms preprocess, 163.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 162.7ms\n",
      "Speed: 3.5ms preprocess, 162.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 164.0ms\n",
      "Speed: 2.5ms preprocess, 164.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 159.9ms\n",
      "Speed: 2.0ms preprocess, 159.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 160.2ms\n",
      "Speed: 3.0ms preprocess, 160.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.3ms\n",
      "Speed: 2.0ms preprocess, 165.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.5ms\n",
      "Speed: 2.0ms preprocess, 164.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.2ms\n",
      "Speed: 3.0ms preprocess, 164.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.5ms\n",
      "Speed: 3.0ms preprocess, 163.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 197.5ms\n",
      "Speed: 2.0ms preprocess, 197.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 159.9ms\n",
      "Speed: 3.0ms preprocess, 159.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 151.9ms\n",
      "Speed: 1.0ms preprocess, 151.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 157.0ms\n",
      "Speed: 3.0ms preprocess, 157.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 151.0ms\n",
      "Speed: 1.0ms preprocess, 151.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 148.4ms\n",
      "Speed: 1.5ms preprocess, 148.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 150.0ms\n",
      "Speed: 3.0ms preprocess, 150.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 153.4ms\n",
      "Speed: 3.0ms preprocess, 153.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 156.5ms\n",
      "Speed: 1.5ms preprocess, 156.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 163.2ms\n",
      "Speed: 3.0ms preprocess, 163.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 164.5ms\n",
      "Speed: 2.0ms preprocess, 164.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 160.5ms\n",
      "Speed: 3.5ms preprocess, 160.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 162.6ms\n",
      "Speed: 1.5ms preprocess, 162.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 163.5ms\n",
      "Speed: 2.0ms preprocess, 163.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 158.0ms\n",
      "Speed: 3.0ms preprocess, 158.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 162.9ms\n",
      "Speed: 2.0ms preprocess, 162.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 170.0ms\n",
      "Speed: 3.0ms preprocess, 170.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 160.3ms\n",
      "Speed: 3.0ms preprocess, 160.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 162.5ms\n",
      "Speed: 3.0ms preprocess, 162.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 161.0ms\n",
      "Speed: 3.0ms preprocess, 161.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 159.5ms\n",
      "Speed: 3.0ms preprocess, 159.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 F, 160.0ms\n",
      "Speed: 3.5ms preprocess, 160.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 C, 163.9ms\n",
      "Speed: 3.0ms preprocess, 163.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 162.5ms\n",
      "Speed: 3.0ms preprocess, 162.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 166.4ms\n",
      "Speed: 3.0ms preprocess, 166.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 165.0ms\n",
      "Speed: 3.5ms preprocess, 165.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 165.1ms\n",
      "Speed: 3.0ms preprocess, 165.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 164.1ms\n",
      "Speed: 3.0ms preprocess, 164.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 160.4ms\n",
      "Speed: 2.0ms preprocess, 160.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 162.1ms\n",
      "Speed: 2.0ms preprocess, 162.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 162.4ms\n",
      "Speed: 2.0ms preprocess, 162.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 166.5ms\n",
      "Speed: 2.0ms preprocess, 166.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 164.6ms\n",
      "Speed: 3.0ms preprocess, 164.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 157.4ms\n",
      "Speed: 2.0ms preprocess, 157.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 166.5ms\n",
      "Speed: 3.0ms preprocess, 166.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 169.8ms\n",
      "Speed: 3.5ms preprocess, 169.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 160.9ms\n",
      "Speed: 3.0ms preprocess, 160.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 168.4ms\n",
      "Speed: 3.0ms preprocess, 168.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 161.1ms\n",
      "Speed: 2.0ms preprocess, 161.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 155.7ms\n",
      "Speed: 2.0ms preprocess, 155.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 165.7ms\n",
      "Speed: 2.0ms preprocess, 165.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 166.4ms\n",
      "Speed: 2.5ms preprocess, 166.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 167.4ms\n",
      "Speed: 2.0ms preprocess, 167.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 162.0ms\n",
      "Speed: 2.5ms preprocess, 162.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 158.6ms\n",
      "Speed: 1.5ms preprocess, 158.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 149.0ms\n",
      "Speed: 3.0ms preprocess, 149.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 147.6ms\n",
      "Speed: 2.5ms preprocess, 147.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 151.8ms\n",
      "Speed: 2.0ms preprocess, 151.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 153.4ms\n",
      "Speed: 2.0ms preprocess, 153.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 150.9ms\n",
      "Speed: 1.0ms preprocess, 150.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 143.9ms\n",
      "Speed: 1.0ms preprocess, 143.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 160.5ms\n",
      "Speed: 3.0ms preprocess, 160.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 164.4ms\n",
      "Speed: 2.5ms preprocess, 164.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 159.3ms\n",
      "Speed: 2.0ms preprocess, 159.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 162.5ms\n",
      "Speed: 2.0ms preprocess, 162.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 163.8ms\n",
      "Speed: 2.0ms preprocess, 163.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 162.9ms\n",
      "Speed: 3.5ms preprocess, 162.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 164.2ms\n",
      "Speed: 3.0ms preprocess, 164.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 165.2ms\n",
      "Speed: 2.0ms preprocess, 165.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 164.4ms\n",
      "Speed: 2.1ms preprocess, 164.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 164.0ms\n",
      "Speed: 1.0ms preprocess, 164.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 152.4ms\n",
      "Speed: 3.0ms preprocess, 152.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 143.9ms\n",
      "Speed: 3.0ms preprocess, 143.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 146.9ms\n",
      "Speed: 2.5ms preprocess, 146.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 147.5ms\n",
      "Speed: 2.5ms preprocess, 147.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 153.8ms\n",
      "Speed: 2.0ms preprocess, 153.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 149.9ms\n",
      "Speed: 2.0ms preprocess, 149.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 157.0ms\n",
      "Speed: 1.5ms preprocess, 157.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 153.8ms\n",
      "Speed: 3.0ms preprocess, 153.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 160.9ms\n",
      "Speed: 2.5ms preprocess, 160.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 161.7ms\n",
      "Speed: 3.0ms preprocess, 161.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 155.7ms\n",
      "Speed: 3.0ms preprocess, 155.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 155.3ms\n",
      "Speed: 2.5ms preprocess, 155.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 151.7ms\n",
      "Speed: 1.5ms preprocess, 151.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 150.4ms\n",
      "Speed: 1.0ms preprocess, 150.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 149.7ms\n",
      "Speed: 4.0ms preprocess, 149.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 155.4ms\n",
      "Speed: 3.0ms preprocess, 155.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 148.3ms\n",
      "Speed: 3.0ms preprocess, 148.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 1 G, 155.3ms\n",
      "Speed: 2.5ms preprocess, 155.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 151.0ms\n",
      "Speed: 3.0ms preprocess, 151.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 1 G, 161.7ms\n",
      "Speed: 2.0ms preprocess, 161.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.1ms\n",
      "Speed: 3.1ms preprocess, 163.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 163.9ms\n",
      "Speed: 3.0ms preprocess, 163.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 160.6ms\n",
      "Speed: 2.5ms preprocess, 160.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 155.1ms\n",
      "Speed: 2.0ms preprocess, 155.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 150.4ms\n",
      "Speed: 1.0ms preprocess, 150.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 148.5ms\n",
      "Speed: 2.6ms preprocess, 148.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 150.3ms\n",
      "Speed: 3.0ms preprocess, 150.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 155.9ms\n",
      "Speed: 2.0ms preprocess, 155.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 157.5ms\n",
      "Speed: 1.5ms preprocess, 157.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 153.0ms\n",
      "Speed: 3.0ms preprocess, 153.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 152.9ms\n",
      "Speed: 3.0ms preprocess, 152.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 154.2ms\n",
      "Speed: 2.0ms preprocess, 154.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 163.9ms\n",
      "Speed: 3.0ms preprocess, 163.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 167.6ms\n",
      "Speed: 3.5ms preprocess, 167.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 167.2ms\n",
      "Speed: 2.0ms preprocess, 167.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 161.9ms\n",
      "Speed: 1.5ms preprocess, 161.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.2ms\n",
      "Speed: 2.0ms preprocess, 161.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 156.6ms\n",
      "Speed: 3.5ms preprocess, 156.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 174.4ms\n",
      "Speed: 2.0ms preprocess, 174.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.7ms\n",
      "Speed: 3.5ms preprocess, 160.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 158.0ms\n",
      "Speed: 1.0ms preprocess, 158.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 F, 150.0ms\n",
      "Speed: 2.0ms preprocess, 150.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 153.0ms\n",
      "Speed: 1.0ms preprocess, 153.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 149.5ms\n",
      "Speed: 3.5ms preprocess, 149.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.8ms\n",
      "Speed: 3.0ms preprocess, 160.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 166.7ms\n",
      "Speed: 3.0ms preprocess, 166.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 161.8ms\n",
      "Speed: 3.1ms preprocess, 161.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.0ms\n",
      "Speed: 3.5ms preprocess, 164.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 153.3ms\n",
      "Speed: 2.0ms preprocess, 153.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 181.0ms\n",
      "Speed: 2.0ms preprocess, 181.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 154.1ms\n",
      "Speed: 2.0ms preprocess, 154.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 159.1ms\n",
      "Speed: 2.5ms preprocess, 159.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.1ms\n",
      "Speed: 1.5ms preprocess, 163.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 151.6ms\n",
      "Speed: 3.1ms preprocess, 151.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 157.8ms\n",
      "Speed: 4.0ms preprocess, 157.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 162.2ms\n",
      "Speed: 3.0ms preprocess, 162.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.9ms\n",
      "Speed: 2.0ms preprocess, 164.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.1ms\n",
      "Speed: 3.0ms preprocess, 164.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.0ms\n",
      "Speed: 1.5ms preprocess, 164.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.1ms\n",
      "Speed: 2.0ms preprocess, 160.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 155.6ms\n",
      "Speed: 3.5ms preprocess, 155.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 152.0ms\n",
      "Speed: 1.0ms preprocess, 152.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 154.0ms\n",
      "Speed: 3.0ms preprocess, 154.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 152.0ms\n",
      "Speed: 3.0ms preprocess, 152.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 162.6ms\n",
      "Speed: 3.0ms preprocess, 162.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 152.9ms\n",
      "Speed: 2.0ms preprocess, 152.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 162.3ms\n",
      "Speed: 3.0ms preprocess, 162.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 1 G, 168.4ms\n",
      "Speed: 2.5ms preprocess, 168.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 171.2ms\n",
      "Speed: 2.0ms preprocess, 171.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 178.6ms\n",
      "Speed: 4.5ms preprocess, 178.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 167.0ms\n",
      "Speed: 3.0ms preprocess, 167.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 162.6ms\n",
      "Speed: 3.0ms preprocess, 162.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.8ms\n",
      "Speed: 3.0ms preprocess, 163.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 175.1ms\n",
      "Speed: 2.0ms preprocess, 175.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 166.6ms\n",
      "Speed: 3.8ms preprocess, 166.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 159.1ms\n",
      "Speed: 3.0ms preprocess, 159.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.4ms\n",
      "Speed: 2.0ms preprocess, 161.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.1ms\n",
      "Speed: 3.0ms preprocess, 164.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.9ms\n",
      "Speed: 2.5ms preprocess, 160.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 170.9ms\n",
      "Speed: 3.5ms preprocess, 170.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 163.5ms\n",
      "Speed: 2.5ms preprocess, 163.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 164.4ms\n",
      "Speed: 3.0ms preprocess, 164.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 154.7ms\n",
      "Speed: 2.0ms preprocess, 154.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 156.5ms\n",
      "Speed: 1.5ms preprocess, 156.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 153.4ms\n",
      "Speed: 2.0ms preprocess, 153.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 156.9ms\n",
      "Speed: 2.0ms preprocess, 156.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 1 G, 152.3ms\n",
      "Speed: 1.5ms preprocess, 152.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 157.0ms\n",
      "Speed: 2.0ms preprocess, 157.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 159.0ms\n",
      "Speed: 3.0ms preprocess, 159.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 152.5ms\n",
      "Speed: 2.0ms preprocess, 152.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 165.9ms\n",
      "Speed: 3.5ms preprocess, 165.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 163.6ms\n",
      "Speed: 3.0ms preprocess, 163.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 170.1ms\n",
      "Speed: 3.0ms preprocess, 170.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 159.9ms\n",
      "Speed: 3.0ms preprocess, 159.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 161.7ms\n",
      "Speed: 1.0ms preprocess, 161.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 154.4ms\n",
      "Speed: 3.0ms preprocess, 154.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 153.8ms\n",
      "Speed: 2.6ms preprocess, 153.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 158.1ms\n",
      "Speed: 2.5ms preprocess, 158.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 157.1ms\n",
      "Speed: 3.0ms preprocess, 157.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 154.2ms\n",
      "Speed: 2.0ms preprocess, 154.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 158.5ms\n",
      "Speed: 2.5ms preprocess, 158.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 157.2ms\n",
      "Speed: 3.0ms preprocess, 157.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 163.9ms\n",
      "Speed: 3.0ms preprocess, 163.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 2 Gs, 167.1ms\n",
      "Speed: 3.0ms preprocess, 167.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 160.9ms\n",
      "Speed: 3.5ms preprocess, 160.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 F, 1 G, 160.6ms\n",
      "Speed: 3.5ms preprocess, 160.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 154.9ms\n",
      "Speed: 2.0ms preprocess, 154.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 157.0ms\n",
      "Speed: 2.0ms preprocess, 157.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 151.9ms\n",
      "Speed: 3.0ms preprocess, 151.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 152.5ms\n",
      "Speed: 3.0ms preprocess, 152.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 156.1ms\n",
      "Speed: 2.0ms preprocess, 156.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 158.3ms\n",
      "Speed: 2.0ms preprocess, 158.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 156.8ms\n",
      "Speed: 3.5ms preprocess, 156.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 159.7ms\n",
      "Speed: 2.0ms preprocess, 159.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 167.0ms\n",
      "Speed: 3.0ms preprocess, 167.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 G, 164.5ms\n",
      "Speed: 3.0ms preprocess, 164.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 169.1ms\n",
      "Speed: 2.5ms preprocess, 169.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 162.8ms\n",
      "Speed: 2.0ms preprocess, 162.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 160.4ms\n",
      "Speed: 3.0ms preprocess, 160.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 158.3ms\n",
      "Speed: 2.0ms preprocess, 158.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 152.5ms\n",
      "Speed: 2.5ms preprocess, 152.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 158.4ms\n",
      "Speed: 2.0ms preprocess, 158.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 157.5ms\n",
      "Speed: 3.0ms preprocess, 157.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 151.9ms\n",
      "Speed: 1.5ms preprocess, 151.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.0ms\n",
      "Speed: 1.5ms preprocess, 163.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 150.5ms\n",
      "Speed: 1.5ms preprocess, 150.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 158.0ms\n",
      "Speed: 1.0ms preprocess, 158.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.4ms\n",
      "Speed: 2.1ms preprocess, 161.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 162.5ms\n",
      "Speed: 1.5ms preprocess, 162.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 167.9ms\n",
      "Speed: 3.0ms preprocess, 167.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 168.0ms\n",
      "Speed: 2.0ms preprocess, 168.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 166.8ms\n",
      "Speed: 3.0ms preprocess, 166.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 160.0ms\n",
      "Speed: 3.0ms preprocess, 160.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 155.4ms\n",
      "Speed: 1.0ms preprocess, 155.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 152.4ms\n",
      "Speed: 3.0ms preprocess, 152.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 166.1ms\n",
      "Speed: 1.0ms preprocess, 166.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.1ms\n",
      "Speed: 2.0ms preprocess, 165.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 170.0ms\n",
      "Speed: 2.5ms preprocess, 170.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.5ms\n",
      "Speed: 3.0ms preprocess, 161.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 168.3ms\n",
      "Speed: 2.0ms preprocess, 168.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.2ms\n",
      "Speed: 3.0ms preprocess, 165.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 167.7ms\n",
      "Speed: 3.0ms preprocess, 167.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 157.2ms\n",
      "Speed: 3.0ms preprocess, 157.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 165.3ms\n",
      "Speed: 1.2ms preprocess, 165.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import pygame\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 학습된 모델 로드\n",
    "model = YOLO('C:/Users/3gkim/OneDrive/Desktop/YOLO/best.pt')\n",
    "\n",
    "# 내장 카메라 사용\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video stream.\")\n",
    "    exit()\n",
    "\n",
    "# 임계값 설정\n",
    "threshold = 0.7\n",
    "\n",
    "# pygame 초기화\n",
    "pygame.mixer.init()\n",
    "\n",
    "# 음성 파일 경로 설정\n",
    "voice_path = 'C:/Users/3gkim/OneDrive/Desktop/YOLO/voice'\n",
    "\n",
    "# 마지막으로 감지된 시간과 레이블 저장\n",
    "last_played = {\n",
    "    'Am': 0,\n",
    "    'F': 0,\n",
    "    'C': 0,\n",
    "    'G': 0\n",
    "}\n",
    "# 음성을 재생할 최소 시간 간격 (초)\n",
    "cooldown_time = 3\n",
    "\n",
    "# 감지된 레이블에 따른 음성 파일 재생 함수\n",
    "def play_voice(label):\n",
    "    current_time = time.time()\n",
    "    if current_time - last_played[label] > cooldown_time:\n",
    "        voice_files = {\n",
    "            'Am': 'Amvoice.mp3',\n",
    "            'F': 'Fvoice.mp3',\n",
    "            'C': 'Cvoice.mp3',\n",
    "            'G': 'Gvoice.mp3'\n",
    "        }\n",
    "        if label in voice_files:\n",
    "            file_path = os.path.join(voice_path, voice_files[label])\n",
    "            if os.path.exists(file_path):\n",
    "                pygame.mixer.music.load(file_path)\n",
    "                pygame.mixer.music.play()\n",
    "                last_played[label] = current_time\n",
    "\n",
    "while True:\n",
    "    # 프레임 읽기\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read frame\")\n",
    "        break\n",
    "\n",
    "    # YOLO 모델로 예측 수행\n",
    "    try:\n",
    "        results = model.predict(frame)\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction failed: {e}\")\n",
    "        break\n",
    "\n",
    "    # 예측 결과를 프레임에 표시\n",
    "    annotated_frame = frame.copy()\n",
    "    detected_labels = set()\n",
    "\n",
    "    for result in results:\n",
    "        try:\n",
    "            boxes = result.boxes.xyxy.numpy()  # 예측된 bounding box 좌표\n",
    "            scores = result.boxes.conf.numpy()  # 예측된 confidence scores\n",
    "            class_ids = result.boxes.cls.numpy()  # 예측된 클래스 ID\n",
    "            labels = model.names  # 클래스 이름 (result.names가 아닌 model.names로 접근)\n",
    "\n",
    "            for box, score, class_id in zip(boxes, scores, class_ids):\n",
    "                if score >= threshold:\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    label = labels[int(class_id)]\n",
    "                    detected_labels.add(label)\n",
    "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    cv2.putText(annotated_frame, f'{label} {score:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing results: {e}\")\n",
    "\n",
    "    # 각 코드가 탐지되면 음성 출력\n",
    "    for label in detected_labels:\n",
    "        play_voice(label)\n",
    "\n",
    "    # 프레임 표시\n",
    "    try:\n",
    "        cv2.imshow('YOLO Detection', annotated_frame)\n",
    "    except Exception as e:\n",
    "        print(f\"Error displaying frame: {e}\")\n",
    "\n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 자원 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "pygame.mixer.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x480 (no detections), 146.1ms\n",
      "Speed: 4.0ms preprocess, 146.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 174.7ms\n",
      "Speed: 2.5ms preprocess, 174.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 148.7ms\n",
      "Speed: 2.0ms preprocess, 148.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 136.6ms\n",
      "Speed: 1.5ms preprocess, 136.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 182.2ms\n",
      "Speed: 2.0ms preprocess, 182.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 184.6ms\n",
      "Speed: 4.0ms preprocess, 184.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 195.5ms\n",
      "Speed: 3.0ms preprocess, 195.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 180.2ms\n",
      "Speed: 2.5ms preprocess, 180.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 178.8ms\n",
      "Speed: 2.5ms preprocess, 178.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 145.8ms\n",
      "Speed: 2.0ms preprocess, 145.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 148.3ms\n",
      "Speed: 2.0ms preprocess, 148.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 153.8ms\n",
      "Speed: 2.9ms preprocess, 153.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 152.3ms\n",
      "Speed: 3.0ms preprocess, 152.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 157.5ms\n",
      "Speed: 1.0ms preprocess, 157.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 151.8ms\n",
      "Speed: 2.0ms preprocess, 151.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 163.0ms\n",
      "Speed: 1.0ms preprocess, 163.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.9ms\n",
      "Speed: 2.0ms preprocess, 161.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 161.1ms\n",
      "Speed: 3.5ms preprocess, 161.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 139.7ms\n",
      "Speed: 1.0ms preprocess, 139.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 156.8ms\n",
      "Speed: 3.5ms preprocess, 156.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 163.4ms\n",
      "Speed: 3.0ms preprocess, 163.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 159.1ms\n",
      "Speed: 2.5ms preprocess, 159.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 160.4ms\n",
      "Speed: 3.5ms preprocess, 160.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 156.4ms\n",
      "Speed: 2.0ms preprocess, 156.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 150.3ms\n",
      "Speed: 3.5ms preprocess, 150.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 154.2ms\n",
      "Speed: 2.0ms preprocess, 154.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 150.6ms\n",
      "Speed: 2.0ms preprocess, 150.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 F, 1 G, 128.8ms\n",
      "Speed: 1.2ms preprocess, 128.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 152.3ms\n",
      "Speed: 2.5ms preprocess, 152.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 F, 1 G, 148.8ms\n",
      "Speed: 3.0ms preprocess, 148.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 G, 150.3ms\n",
      "Speed: 1.0ms preprocess, 150.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 G, 152.4ms\n",
      "Speed: 3.0ms preprocess, 152.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 F, 1 G, 150.5ms\n",
      "Speed: 3.0ms preprocess, 150.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 161.4ms\n",
      "Speed: 3.0ms preprocess, 161.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 G, 161.9ms\n",
      "Speed: 3.5ms preprocess, 161.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 153.4ms\n",
      "Speed: 1.4ms preprocess, 153.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 138.1ms\n",
      "Speed: 2.0ms preprocess, 138.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 156.9ms\n",
      "Speed: 1.5ms preprocess, 156.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 155.9ms\n",
      "Speed: 3.0ms preprocess, 155.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 163.1ms\n",
      "Speed: 3.5ms preprocess, 163.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 162.4ms\n",
      "Speed: 2.5ms preprocess, 162.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 162.4ms\n",
      "Speed: 2.0ms preprocess, 162.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 146.3ms\n",
      "Speed: 3.0ms preprocess, 146.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 150.4ms\n",
      "Speed: 1.0ms preprocess, 150.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 151.3ms\n",
      "Speed: 1.0ms preprocess, 151.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 147.0ms\n",
      "Speed: 1.0ms preprocess, 147.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 147.6ms\n",
      "Speed: 3.0ms preprocess, 147.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 150.6ms\n",
      "Speed: 3.0ms preprocess, 150.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 152.2ms\n",
      "Speed: 1.0ms preprocess, 152.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 150.4ms\n",
      "Speed: 3.0ms preprocess, 150.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 164.2ms\n",
      "Speed: 2.0ms preprocess, 164.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 162.9ms\n",
      "Speed: 3.5ms preprocess, 162.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 158.3ms\n",
      "Speed: 1.0ms preprocess, 158.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 152.7ms\n",
      "Speed: 2.0ms preprocess, 152.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 154.1ms\n",
      "Speed: 3.0ms preprocess, 154.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 153.7ms\n",
      "Speed: 3.0ms preprocess, 153.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 155.6ms\n",
      "Speed: 3.0ms preprocess, 155.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 155.6ms\n",
      "Speed: 2.5ms preprocess, 155.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 154.7ms\n",
      "Speed: 1.0ms preprocess, 154.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 153.7ms\n",
      "Speed: 1.5ms preprocess, 153.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 151.7ms\n",
      "Speed: 2.5ms preprocess, 151.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 155.8ms\n",
      "Speed: 3.0ms preprocess, 155.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 159.2ms\n",
      "Speed: 2.0ms preprocess, 159.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 161.2ms\n",
      "Speed: 2.5ms preprocess, 161.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 136.8ms\n",
      "Speed: 1.9ms preprocess, 136.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 156.5ms\n",
      "Speed: 2.0ms preprocess, 156.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 146.8ms\n",
      "Speed: 2.5ms preprocess, 146.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 146.7ms\n",
      "Speed: 3.0ms preprocess, 146.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 151.3ms\n",
      "Speed: 3.0ms preprocess, 151.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 150.3ms\n",
      "Speed: 2.0ms preprocess, 150.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 148.5ms\n",
      "Speed: 2.0ms preprocess, 148.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 151.3ms\n",
      "Speed: 3.5ms preprocess, 151.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 151.3ms\n",
      "Speed: 1.5ms preprocess, 151.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 F, 139.9ms\n",
      "Speed: 1.0ms preprocess, 139.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 F, 147.3ms\n",
      "Speed: 1.0ms preprocess, 147.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 F, 156.4ms\n",
      "Speed: 3.0ms preprocess, 156.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 F, 157.5ms\n",
      "Speed: 2.5ms preprocess, 157.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 F, 155.4ms\n",
      "Speed: 1.0ms preprocess, 155.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 F, 158.5ms\n",
      "Speed: 3.5ms preprocess, 158.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 154.4ms\n",
      "Speed: 2.0ms preprocess, 154.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 F, 153.8ms\n",
      "Speed: 2.5ms preprocess, 153.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 F, 148.3ms\n",
      "Speed: 2.0ms preprocess, 148.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 151.8ms\n",
      "Speed: 2.0ms preprocess, 151.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 1 F, 153.8ms\n",
      "Speed: 2.0ms preprocess, 153.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 147.9ms\n",
      "Speed: 3.0ms preprocess, 147.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 149.1ms\n",
      "Speed: 2.0ms preprocess, 149.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 150.8ms\n",
      "Speed: 2.0ms preprocess, 150.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 150.8ms\n",
      "Speed: 3.0ms preprocess, 150.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 150.9ms\n",
      "Speed: 1.0ms preprocess, 150.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 153.9ms\n",
      "Speed: 2.0ms preprocess, 153.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 154.9ms\n",
      "Speed: 2.0ms preprocess, 154.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 138.3ms\n",
      "Speed: 1.0ms preprocess, 138.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 149.0ms\n",
      "Speed: 2.0ms preprocess, 149.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 160.9ms\n",
      "Speed: 3.5ms preprocess, 160.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 158.8ms\n",
      "Speed: 1.6ms preprocess, 158.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 152.3ms\n",
      "Speed: 2.0ms preprocess, 152.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 145.4ms\n",
      "Speed: 2.0ms preprocess, 145.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 148.6ms\n",
      "Speed: 2.5ms preprocess, 148.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 153.0ms\n",
      "Speed: 2.0ms preprocess, 153.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 158.4ms\n",
      "Speed: 1.5ms preprocess, 158.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 154.5ms\n",
      "Speed: 2.0ms preprocess, 154.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 148.8ms\n",
      "Speed: 2.0ms preprocess, 148.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 146.7ms\n",
      "Speed: 1.0ms preprocess, 146.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 151.8ms\n",
      "Speed: 3.0ms preprocess, 151.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 156.4ms\n",
      "Speed: 2.0ms preprocess, 156.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 162.8ms\n",
      "Speed: 2.5ms preprocess, 162.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 160.1ms\n",
      "Speed: 2.0ms preprocess, 160.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 161.5ms\n",
      "Speed: 2.0ms preprocess, 161.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 161.9ms\n",
      "Speed: 4.0ms preprocess, 161.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 150.8ms\n",
      "Speed: 2.0ms preprocess, 150.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 C, 139.5ms\n",
      "Speed: 1.0ms preprocess, 139.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 152.0ms\n",
      "Speed: 2.0ms preprocess, 152.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 148.8ms\n",
      "Speed: 3.0ms preprocess, 148.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 151.1ms\n",
      "Speed: 2.0ms preprocess, 151.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 145.1ms\n",
      "Speed: 3.0ms preprocess, 145.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 152.4ms\n",
      "Speed: 2.5ms preprocess, 152.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 152.3ms\n",
      "Speed: 2.0ms preprocess, 152.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 156.0ms\n",
      "Speed: 2.0ms preprocess, 156.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 159.9ms\n",
      "Speed: 1.0ms preprocess, 159.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 159.4ms\n",
      "Speed: 2.0ms preprocess, 159.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 157.4ms\n",
      "Speed: 1.0ms preprocess, 157.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 160.3ms\n",
      "Speed: 2.5ms preprocess, 160.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 149.5ms\n",
      "Speed: 1.5ms preprocess, 149.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 153.8ms\n",
      "Speed: 2.0ms preprocess, 153.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 148.3ms\n",
      "Speed: 2.0ms preprocess, 148.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 146.7ms\n",
      "Speed: 3.5ms preprocess, 146.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 148.3ms\n",
      "Speed: 1.5ms preprocess, 148.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 155.8ms\n",
      "Speed: 1.0ms preprocess, 155.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 G, 148.7ms\n",
      "Speed: 3.5ms preprocess, 148.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 136.3ms\n",
      "Speed: 2.0ms preprocess, 136.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 152.9ms\n",
      "Speed: 1.0ms preprocess, 152.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 152.6ms\n",
      "Speed: 1.0ms preprocess, 152.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 3 Ams, 157.8ms\n",
      "Speed: 4.5ms preprocess, 157.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 3 Ams, 152.0ms\n",
      "Speed: 2.0ms preprocess, 152.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 162.1ms\n",
      "Speed: 3.5ms preprocess, 162.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 160.7ms\n",
      "Speed: 2.0ms preprocess, 160.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 Am, 155.8ms\n",
      "Speed: 2.0ms preprocess, 155.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 2 Ams, 149.3ms\n",
      "Speed: 3.0ms preprocess, 149.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 137.7ms\n",
      "Speed: 2.0ms preprocess, 137.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 151.3ms\n",
      "Speed: 4.0ms preprocess, 151.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 149.8ms\n",
      "Speed: 2.0ms preprocess, 149.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 153.3ms\n",
      "Speed: 3.0ms preprocess, 153.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 149.3ms\n",
      "Speed: 2.0ms preprocess, 149.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 152.3ms\n",
      "Speed: 1.5ms preprocess, 152.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 151.3ms\n",
      "Speed: 2.2ms preprocess, 151.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 156.2ms\n",
      "Speed: 2.0ms preprocess, 156.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 159.4ms\n",
      "Speed: 3.5ms preprocess, 159.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 159.4ms\n",
      "Speed: 2.0ms preprocess, 159.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 155.9ms\n",
      "Speed: 2.0ms preprocess, 155.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 148.9ms\n",
      "Speed: 2.0ms preprocess, 148.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 157.8ms\n",
      "Speed: 2.0ms preprocess, 157.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import pygame\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 학습된 모델 로드\n",
    "model = YOLO('C:/Users/3gkim/OneDrive/Desktop/YOLO/best.pt')\n",
    "\n",
    "# 내장 카메라 사용\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video stream.\")\n",
    "    exit()\n",
    "\n",
    "# 임계값 설정\n",
    "threshold = 0.7\n",
    "\n",
    "# pygame 초기화\n",
    "pygame.mixer.init()\n",
    "\n",
    "# 음성 파일 경로 설정\n",
    "voice_path = 'C:/Users/3gkim/OneDrive/Desktop/YOLO/voice'\n",
    "\n",
    "# 마지막으로 감지된 시간과 레이블 저장\n",
    "last_played = {\n",
    "    'Am': 0,\n",
    "}\n",
    "# 음성을 재생할 최소 시간 간격 (초)\n",
    "cooldown_time = 5.3\n",
    "\n",
    "# 감지된 레이블에 따른 음성 파일 재생 함수\n",
    "def play_voice(filename):\n",
    "    file_path = os.path.join(voice_path, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        pygame.mixer.music.load(file_path)\n",
    "        pygame.mixer.music.play()\n",
    "        while pygame.mixer.music.get_busy():\n",
    "            pass\n",
    "\n",
    "while True:\n",
    "    # 프레임 읽기\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read frame\")\n",
    "        break\n",
    "\n",
    "    # YOLO 모델로 예측 수행\n",
    "    results = model.predict(frame)\n",
    "\n",
    "    # 예측 결과를 프레임에 표시\n",
    "    annotated_frame = frame.copy()\n",
    "    detected_labels = set()\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes.xyxy.numpy()  # 예측된 bounding box 좌표\n",
    "        scores = result.boxes.conf.numpy()  # 예측된 confidence scores\n",
    "        class_ids = result.boxes.cls.numpy()  # 예측된 클래스 ID\n",
    "        labels = model.names  # 클래스 이름 (result.names가 아닌 model.names로 접근)\n",
    "\n",
    "        for box, score, class_id in zip(boxes, scores, class_ids):\n",
    "            if score >= threshold:\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                label = labels[int(class_id)]\n",
    "                detected_labels.add(label)\n",
    "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                cv2.putText(annotated_frame, f'{label} {score:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    # Am 코드만 감지\n",
    "    current_time = time.time()\n",
    "    if 'Am' in detected_labels:\n",
    "        if current_time - last_played['Am'] > cooldown_time:\n",
    "            play_voice(\"Amvoice.mp3\")\n",
    "            last_played['Am'] = current_time\n",
    "    else:\n",
    "        if current_time - last_played['Am'] > cooldown_time:\n",
    "            play_voice(\"Am_fingering.mp3\")\n",
    "            last_played['Am'] = current_time\n",
    "\n",
    "    # 프레임 표시\n",
    "    cv2.imshow('YOLO Detection', annotated_frame)\n",
    "\n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 자원 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "pygame.mixer.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
